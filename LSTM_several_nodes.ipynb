{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservoir_demand</th>\n",
       "      <th>node_1_demand</th>\n",
       "      <th>node_2_demand</th>\n",
       "      <th>node_3_demand</th>\n",
       "      <th>node_4_demand</th>\n",
       "      <th>node_5_demand</th>\n",
       "      <th>node_6_demand</th>\n",
       "      <th>node_7_demand</th>\n",
       "      <th>node_8_demand</th>\n",
       "      <th>node_9_demand</th>\n",
       "      <th>...</th>\n",
       "      <th>link_23_flow</th>\n",
       "      <th>link_24_flow</th>\n",
       "      <th>link_25_flow</th>\n",
       "      <th>link_26_flow</th>\n",
       "      <th>link_27_flow</th>\n",
       "      <th>link_28_flow</th>\n",
       "      <th>link_29_flow</th>\n",
       "      <th>link_30_flow</th>\n",
       "      <th>link_31_flow</th>\n",
       "      <th>link_32_flow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>-3348.0</td>\n",
       "      <td>154.8</td>\n",
       "      <td>169.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>118.8</td>\n",
       "      <td>169.2</td>\n",
       "      <td>234.0</td>\n",
       "      <td>86.4</td>\n",
       "      <td>82.8</td>\n",
       "      <td>104.4</td>\n",
       "      <td>...</td>\n",
       "      <td>439.2</td>\n",
       "      <td>-205.2</td>\n",
       "      <td>-75.6</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>118.8</td>\n",
       "      <td>68.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>212.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:30:00</th>\n",
       "      <td>-2959.2</td>\n",
       "      <td>136.8</td>\n",
       "      <td>147.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>237.6</td>\n",
       "      <td>79.2</td>\n",
       "      <td>75.6</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>392.4</td>\n",
       "      <td>-187.2</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>-21.6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>61.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>183.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>-2692.8</td>\n",
       "      <td>129.6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>104.4</td>\n",
       "      <td>133.2</td>\n",
       "      <td>205.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>349.2</td>\n",
       "      <td>-176.4</td>\n",
       "      <td>-64.8</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>93.6</td>\n",
       "      <td>50.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-39.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>151.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:30:00</th>\n",
       "      <td>-2379.6</td>\n",
       "      <td>104.4</td>\n",
       "      <td>100.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>122.4</td>\n",
       "      <td>180.0</td>\n",
       "      <td>68.4</td>\n",
       "      <td>57.6</td>\n",
       "      <td>82.8</td>\n",
       "      <td>...</td>\n",
       "      <td>316.8</td>\n",
       "      <td>-158.4</td>\n",
       "      <td>-54.0</td>\n",
       "      <td>-10.8</td>\n",
       "      <td>79.2</td>\n",
       "      <td>46.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-32.4</td>\n",
       "      <td>50.4</td>\n",
       "      <td>140.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>-2228.4</td>\n",
       "      <td>104.4</td>\n",
       "      <td>104.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>79.2</td>\n",
       "      <td>122.4</td>\n",
       "      <td>183.6</td>\n",
       "      <td>68.4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>277.2</td>\n",
       "      <td>-144.0</td>\n",
       "      <td>-57.6</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-32.4</td>\n",
       "      <td>43.2</td>\n",
       "      <td>118.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:30:00</th>\n",
       "      <td>-5306.4</td>\n",
       "      <td>205.2</td>\n",
       "      <td>208.8</td>\n",
       "      <td>39.6</td>\n",
       "      <td>183.6</td>\n",
       "      <td>284.4</td>\n",
       "      <td>316.8</td>\n",
       "      <td>176.4</td>\n",
       "      <td>133.2</td>\n",
       "      <td>129.6</td>\n",
       "      <td>...</td>\n",
       "      <td>604.8</td>\n",
       "      <td>-259.2</td>\n",
       "      <td>32.4</td>\n",
       "      <td>115.2</td>\n",
       "      <td>169.2</td>\n",
       "      <td>100.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>-100.8</td>\n",
       "      <td>122.4</td>\n",
       "      <td>309.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>-4910.4</td>\n",
       "      <td>208.8</td>\n",
       "      <td>183.6</td>\n",
       "      <td>39.6</td>\n",
       "      <td>154.8</td>\n",
       "      <td>252.0</td>\n",
       "      <td>295.2</td>\n",
       "      <td>165.6</td>\n",
       "      <td>133.2</td>\n",
       "      <td>133.2</td>\n",
       "      <td>...</td>\n",
       "      <td>565.2</td>\n",
       "      <td>-241.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>100.8</td>\n",
       "      <td>154.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-75.6</td>\n",
       "      <td>100.8</td>\n",
       "      <td>288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:30:00</th>\n",
       "      <td>-4683.6</td>\n",
       "      <td>187.2</td>\n",
       "      <td>183.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>147.6</td>\n",
       "      <td>230.4</td>\n",
       "      <td>320.4</td>\n",
       "      <td>147.6</td>\n",
       "      <td>118.8</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>529.2</td>\n",
       "      <td>-226.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>100.8</td>\n",
       "      <td>147.6</td>\n",
       "      <td>86.4</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-86.4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>266.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>-4262.4</td>\n",
       "      <td>180.0</td>\n",
       "      <td>165.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>136.8</td>\n",
       "      <td>223.2</td>\n",
       "      <td>241.2</td>\n",
       "      <td>147.6</td>\n",
       "      <td>115.2</td>\n",
       "      <td>111.6</td>\n",
       "      <td>...</td>\n",
       "      <td>496.8</td>\n",
       "      <td>-208.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>93.6</td>\n",
       "      <td>133.2</td>\n",
       "      <td>79.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>-75.6</td>\n",
       "      <td>97.2</td>\n",
       "      <td>255.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:30:00</th>\n",
       "      <td>-3808.8</td>\n",
       "      <td>176.4</td>\n",
       "      <td>169.2</td>\n",
       "      <td>25.2</td>\n",
       "      <td>122.4</td>\n",
       "      <td>201.6</td>\n",
       "      <td>241.2</td>\n",
       "      <td>122.4</td>\n",
       "      <td>100.8</td>\n",
       "      <td>93.6</td>\n",
       "      <td>...</td>\n",
       "      <td>421.2</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>86.4</td>\n",
       "      <td>118.8</td>\n",
       "      <td>68.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>-68.4</td>\n",
       "      <td>86.4</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87600 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     reservoir_demand  node_1_demand  node_2_demand  \\\n",
       "Timestamp                                                             \n",
       "2017-01-01 00:00:00           -3348.0          154.8          169.2   \n",
       "2017-01-01 00:30:00           -2959.2          136.8          147.6   \n",
       "2017-01-01 01:00:00           -2692.8          129.6          126.0   \n",
       "2017-01-01 01:30:00           -2379.6          104.4          100.8   \n",
       "2017-01-01 02:00:00           -2228.4          104.4          104.4   \n",
       "...                               ...            ...            ...   \n",
       "2017-12-31 21:30:00           -5306.4          205.2          208.8   \n",
       "2017-12-31 22:00:00           -4910.4          208.8          183.6   \n",
       "2017-12-31 22:30:00           -4683.6          187.2          183.6   \n",
       "2017-12-31 23:00:00           -4262.4          180.0          165.6   \n",
       "2017-12-31 23:30:00           -3808.8          176.4          169.2   \n",
       "\n",
       "                     node_3_demand  node_4_demand  node_5_demand  \\\n",
       "Timestamp                                                          \n",
       "2017-01-01 00:00:00           18.0          118.8          169.2   \n",
       "2017-01-01 00:30:00           18.0          108.0          144.0   \n",
       "2017-01-01 01:00:00           14.4          104.4          133.2   \n",
       "2017-01-01 01:30:00           10.8           86.4          122.4   \n",
       "2017-01-01 02:00:00           10.8           79.2          122.4   \n",
       "...                            ...            ...            ...   \n",
       "2017-12-31 21:30:00           39.6          183.6          284.4   \n",
       "2017-12-31 22:00:00           39.6          154.8          252.0   \n",
       "2017-12-31 22:30:00           36.0          147.6          230.4   \n",
       "2017-12-31 23:00:00           32.4          136.8          223.2   \n",
       "2017-12-31 23:30:00           25.2          122.4          201.6   \n",
       "\n",
       "                     node_6_demand  node_7_demand  node_8_demand  \\\n",
       "Timestamp                                                          \n",
       "2017-01-01 00:00:00          234.0           86.4           82.8   \n",
       "2017-01-01 00:30:00          237.6           79.2           75.6   \n",
       "2017-01-01 01:00:00          205.2           72.0           72.0   \n",
       "2017-01-01 01:30:00          180.0           68.4           57.6   \n",
       "2017-01-01 02:00:00          183.6           68.4           54.0   \n",
       "...                            ...            ...            ...   \n",
       "2017-12-31 21:30:00          316.8          176.4          133.2   \n",
       "2017-12-31 22:00:00          295.2          165.6          133.2   \n",
       "2017-12-31 22:30:00          320.4          147.6          118.8   \n",
       "2017-12-31 23:00:00          241.2          147.6          115.2   \n",
       "2017-12-31 23:30:00          241.2          122.4          100.8   \n",
       "\n",
       "                     node_9_demand  ...  link_23_flow  link_24_flow  \\\n",
       "Timestamp                           ...                               \n",
       "2017-01-01 00:00:00          104.4  ...         439.2        -205.2   \n",
       "2017-01-01 00:30:00           90.0  ...         392.4        -187.2   \n",
       "2017-01-01 01:00:00           90.0  ...         349.2        -176.4   \n",
       "2017-01-01 01:30:00           82.8  ...         316.8        -158.4   \n",
       "2017-01-01 02:00:00           75.6  ...         277.2        -144.0   \n",
       "...                            ...  ...           ...           ...   \n",
       "2017-12-31 21:30:00          129.6  ...         604.8        -259.2   \n",
       "2017-12-31 22:00:00          133.2  ...         565.2        -241.2   \n",
       "2017-12-31 22:30:00          126.0  ...         529.2        -226.8   \n",
       "2017-12-31 23:00:00          111.6  ...         496.8        -208.8   \n",
       "2017-12-31 23:30:00           93.6  ...         421.2        -180.0   \n",
       "\n",
       "                     link_25_flow  link_26_flow  link_27_flow  link_28_flow  \\\n",
       "Timestamp                                                                     \n",
       "2017-01-01 00:00:00         -75.6         -18.0         118.8          68.4   \n",
       "2017-01-01 00:30:00         -72.0         -21.6         108.0          61.2   \n",
       "2017-01-01 01:00:00         -64.8         -18.0          93.6          50.4   \n",
       "2017-01-01 01:30:00         -54.0         -10.8          79.2          46.8   \n",
       "2017-01-01 02:00:00         -57.6         -18.0          72.0          39.6   \n",
       "...                           ...           ...           ...           ...   \n",
       "2017-12-31 21:30:00          32.4         115.2         169.2         100.8   \n",
       "2017-12-31 22:00:00          21.6         100.8         154.8          86.4   \n",
       "2017-12-31 22:30:00          21.6         100.8         147.6          86.4   \n",
       "2017-12-31 23:00:00          21.6          93.6         133.2          79.2   \n",
       "2017-12-31 23:30:00          28.8          86.4         118.8          68.4   \n",
       "\n",
       "                     link_29_flow  link_30_flow  link_31_flow  link_32_flow  \n",
       "Timestamp                                                                    \n",
       "2017-01-01 00:00:00           7.2         -54.0          75.6         212.4  \n",
       "2017-01-01 00:30:00           3.6         -54.0          72.0         183.6  \n",
       "2017-01-01 01:00:00           3.6         -39.6          54.0         151.2  \n",
       "2017-01-01 01:30:00           7.2         -32.4          50.4         140.4  \n",
       "2017-01-01 02:00:00           7.2         -32.4          43.2         118.8  \n",
       "...                           ...           ...           ...           ...  \n",
       "2017-12-31 21:30:00          10.8        -100.8         122.4         309.6  \n",
       "2017-12-31 22:00:00          18.0         -75.6         100.8         288.0  \n",
       "2017-12-31 22:30:00          14.4         -86.4         108.0         266.4  \n",
       "2017-12-31 23:00:00          14.4         -75.6          97.2         255.6  \n",
       "2017-12-31 23:30:00          10.8         -68.4          86.4         216.0  \n",
       "\n",
       "[87600 rows x 96 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/alexellard/Downloads/scenarios_data.csv', header=0, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in, n_out, vars_to_predict=None):\n",
    "    n_vars = data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i-1))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(n_out):\n",
    "        cols.append(df[vars_to_predict].shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in vars_to_predict]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in vars_to_predict]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    return agg\n",
    "\n",
    "values = df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# node 1 indexes\n",
    "target_variable_demand_node1 = [1]\n",
    "target_variable_pressures_node1 = [33]\n",
    "target_variable_flows_node1 = [64]\n",
    "#node 16 indexes\n",
    "target_variable_demand_node16 = [16]\n",
    "target_variable_pressures_node16 = [48]\n",
    "target_variable_flows_node16 = [79]\n",
    "#node 29 indexes\n",
    "target_variable_demand_node29 = [29]\n",
    "target_variable_pressures_node29 = [61]\n",
    "target_variable_flows_node29 = [92]\n",
    "\n",
    "\n",
    "reframed_demand_node1 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_demand_node1)\n",
    "reframed_pressures_node1 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_pressures_node1)\n",
    "reframed_flows_node1 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_flows_node1)\n",
    "\n",
    "reframed_demand_node16 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_demand_node16)\n",
    "reframed_pressures_node16 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_pressures_node16)\n",
    "reframed_flows_node16 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_flows_node16)\n",
    "\n",
    "reframed_demand_node29 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_demand_node29)\n",
    "reframed_pressures_node29 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_pressures_node29)\n",
    "reframed_flows_node29 = series_to_supervised(scaled, 1, 1, vars_to_predict=target_variable_flows_node29)\n",
    "\n",
    "reframed_demand_node1 = reframed_demand_node1.drop(reframed_demand_node1.columns[1], axis=1)\n",
    "reframed_pressures_node1 = reframed_pressures_node1.drop(reframed_pressures_node1.columns[33], axis=1)\n",
    "reframed_flows_node1 = reframed_flows_node1.drop(reframed_flows_node1.columns[64], axis=1)\n",
    "\n",
    "reframed_demand_node16 = reframed_demand_node16.drop(reframed_demand_node16.columns[16], axis=1)\n",
    "reframed_pressures_node16 = reframed_pressures_node16.drop(reframed_pressures_node16.columns[48], axis=1)\n",
    "reframed_flows_node16 = reframed_flows_node16.drop(reframed_flows_node16.columns[79], axis=1)\n",
    "\n",
    "reframed_demand_node29 = reframed_demand_node29.drop(reframed_demand_node29.columns[29], axis=1)\n",
    "reframed_pressures_node29 = reframed_pressures_node29.drop(reframed_pressures_node29.columns[61], axis=1)\n",
    "reframed_flows_node29 = reframed_flows_node29.drop(reframed_flows_node29.columns[92], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "demands = [reframed_demand_node1, reframed_demand_node16, reframed_demand_node29]\n",
    "pressures = [reframed_pressures_node1, reframed_pressures_node16, reframed_pressures_node29]\n",
    "flows = [reframed_flows_node1, reframed_flows_node16, reframed_flows_node29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "WARNING:tensorflow:From /Users/alexellard/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 0.0257 - val_loss: 0.0247\n",
      "Epoch 2/50\n",
      " - 5s - loss: 0.0226 - val_loss: 0.0219\n",
      "Epoch 3/50\n",
      " - 5s - loss: 0.0223 - val_loss: 0.0219\n",
      "Epoch 4/50\n",
      " - 5s - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 5/50\n",
      " - 5s - loss: 0.0220 - val_loss: 0.0220\n",
      "Epoch 6/50\n",
      " - 5s - loss: 0.0220 - val_loss: 0.0221\n",
      "Epoch 7/50\n",
      " - 5s - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 8/50\n",
      " - 5s - loss: 0.0218 - val_loss: 0.0217\n",
      "Epoch 9/50\n",
      " - 5s - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 10/50\n",
      " - 7s - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 11/50\n",
      " - 7s - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 12/50\n",
      " - 7s - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 13/50\n",
      " - 7s - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 14/50\n",
      " - 7s - loss: 0.0215 - val_loss: 0.0212\n",
      "Epoch 15/50\n",
      " - 7s - loss: 0.0215 - val_loss: 0.0211\n",
      "Epoch 16/50\n",
      " - 7s - loss: 0.0214 - val_loss: 0.0210\n",
      "Epoch 17/50\n",
      " - 7s - loss: 0.0214 - val_loss: 0.0215\n",
      "Epoch 18/50\n",
      " - 7s - loss: 0.0214 - val_loss: 0.0211\n",
      "Epoch 19/50\n",
      " - 7s - loss: 0.0213 - val_loss: 0.0209\n",
      "Epoch 20/50\n",
      " - 7s - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 21/50\n",
      " - 7s - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 22/50\n",
      " - 8s - loss: 0.0212 - val_loss: 0.0214\n",
      "Epoch 23/50\n",
      " - 7s - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 24/50\n",
      " - 6s - loss: 0.0212 - val_loss: 0.0208\n",
      "Epoch 25/50\n",
      " - 7s - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 26/50\n",
      " - 7s - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 27/50\n",
      " - 7s - loss: 0.0211 - val_loss: 0.0207\n",
      "Epoch 28/50\n",
      " - 7s - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 29/50\n",
      " - 7s - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 30/50\n",
      " - 6s - loss: 0.0211 - val_loss: 0.0207\n",
      "Epoch 31/50\n",
      " - 6s - loss: 0.0210 - val_loss: 0.0212\n",
      "Epoch 32/50\n",
      " - 6s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 33/50\n",
      " - 6s - loss: 0.0210 - val_loss: 0.0206\n",
      "Epoch 34/50\n",
      " - 6s - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 35/50\n",
      " - 6s - loss: 0.0210 - val_loss: 0.0207\n",
      "Epoch 36/50\n",
      " - 6s - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 37/50\n",
      " - 6s - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 38/50\n",
      " - 6s - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 39/50\n",
      " - 6s - loss: 0.0209 - val_loss: 0.0215\n",
      "Epoch 40/50\n",
      " - 6s - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 41/50\n",
      " - 6s - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 42/50\n",
      " - 6s - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 43/50\n",
      " - 6s - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 44/50\n",
      " - 7s - loss: 0.0207 - val_loss: 0.0211\n",
      "Epoch 45/50\n",
      " - 6s - loss: 0.0208 - val_loss: 0.0204\n",
      "Epoch 46/50\n",
      " - 6s - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 47/50\n",
      " - 6s - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 48/50\n",
      " - 6s - loss: 0.0207 - val_loss: 0.0212\n",
      "Epoch 49/50\n",
      " - 7s - loss: 0.0207 - val_loss: 0.0204\n",
      "Epoch 50/50\n",
      " - 6s - loss: 0.0207 - val_loss: 0.0205\n",
      "Inverted Mean Absolute Error: 174.92969\n",
      "Inverted Test RMSE: 229.011\n",
      "Inverted Test R^2: 0.973\n",
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 0.0243 - val_loss: 0.0294\n",
      "Epoch 2/50\n",
      " - 6s - loss: 0.0164 - val_loss: 0.0186\n",
      "Epoch 3/50\n",
      " - 6s - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 4/50\n",
      " - 7s - loss: 0.0103 - val_loss: 0.0201\n",
      "Epoch 5/50\n",
      " - 6s - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 6/50\n",
      " - 7s - loss: 0.0087 - val_loss: 0.0105\n",
      "Epoch 7/50\n",
      " - 6s - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 8/50\n",
      " - 6s - loss: 0.0082 - val_loss: 0.0100\n",
      "Epoch 9/50\n",
      " - 7s - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 10/50\n",
      " - 6s - loss: 0.0077 - val_loss: 0.0136\n",
      "Epoch 11/50\n",
      " - 7s - loss: 0.0072 - val_loss: 0.0088\n",
      "Epoch 12/50\n",
      " - 7s - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 13/50\n",
      " - 7s - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 14/50\n",
      " - 7s - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 15/50\n",
      " - 6s - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 16/50\n",
      " - 6s - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 17/50\n",
      " - 6s - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 18/50\n",
      " - 7s - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 19/50\n",
      " - 6s - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 20/50\n",
      " - 6s - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 21/50\n",
      " - 7s - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 22/50\n",
      " - 7s - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 23/50\n",
      " - 7s - loss: 0.0062 - val_loss: 0.0099\n",
      "Epoch 24/50\n",
      " - 6s - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 25/50\n",
      " - 6s - loss: 0.0057 - val_loss: 0.0047\n",
      "Epoch 26/50\n",
      " - 7s - loss: 0.0059 - val_loss: 0.0238\n",
      "Epoch 27/50\n",
      " - 7s - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 28/50\n",
      " - 7s - loss: 0.0063 - val_loss: 0.0090\n",
      "Epoch 29/50\n",
      " - 6s - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 30/50\n",
      " - 7s - loss: 0.0055 - val_loss: 0.0049\n",
      "Epoch 31/50\n",
      " - 7s - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 32/50\n",
      " - 6s - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 33/50\n",
      " - 6s - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 34/50\n",
      " - 6s - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 35/50\n",
      " - 7s - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 36/50\n",
      " - 6s - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 37/50\n",
      " - 7s - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 38/50\n",
      " - 6s - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 39/50\n",
      " - 7s - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 40/50\n",
      " - 7s - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 41/50\n",
      " - 7s - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 42/50\n",
      " - 7s - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 43/50\n",
      " - 7s - loss: 0.0053 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      " - 7s - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 45/50\n",
      " - 7s - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 46/50\n",
      " - 7s - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 47/50\n",
      " - 7s - loss: 0.0052 - val_loss: 0.0078\n",
      "Epoch 48/50\n",
      " - 6s - loss: 0.0052 - val_loss: 0.0070\n",
      "Epoch 49/50\n",
      " - 7s - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 50/50\n",
      " - 7s - loss: 0.0050 - val_loss: 0.0052\n",
      "Inverted Mean Absolute Error: 44.188923\n",
      "Inverted Test RMSE: 52.841\n",
      "Inverted Test R^2: 0.999\n",
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 0.0221 - val_loss: 0.0148\n",
      "Epoch 2/50\n",
      " - 6s - loss: 0.0124 - val_loss: 0.0080\n",
      "Epoch 3/50\n",
      " - 6s - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 4/50\n",
      " - 6s - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 5/50\n",
      " - 6s - loss: 0.0081 - val_loss: 0.0062\n",
      "Epoch 6/50\n",
      " - 6s - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 7/50\n",
      " - 6s - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 8/50\n",
      " - 6s - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      " - 6s - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 10/50\n",
      " - 6s - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 11/50\n",
      " - 6s - loss: 0.0074 - val_loss: 0.0069\n",
      "Epoch 12/50\n",
      " - 6s - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 13/50\n",
      " - 6s - loss: 0.0071 - val_loss: 0.0061\n",
      "Epoch 14/50\n",
      " - 7s - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 15/50\n",
      " - 6s - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 16/50\n",
      " - 6s - loss: 0.0071 - val_loss: 0.0070\n",
      "Epoch 17/50\n",
      " - 6s - loss: 0.0069 - val_loss: 0.0062\n",
      "Epoch 18/50\n",
      " - 7s - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 19/50\n",
      " - 6s - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 20/50\n",
      " - 6s - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 21/50\n",
      " - 7s - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 22/50\n",
      " - 6s - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 23/50\n",
      " - 6s - loss: 0.0068 - val_loss: 0.0056\n",
      "Epoch 24/50\n",
      " - 6s - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 25/50\n",
      " - 7s - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 26/50\n",
      " - 6s - loss: 0.0066 - val_loss: 0.0056\n",
      "Epoch 27/50\n",
      " - 6s - loss: 0.0068 - val_loss: 0.0054\n",
      "Epoch 28/50\n",
      " - 6s - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 29/50\n",
      " - 6s - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 30/50\n",
      " - 6s - loss: 0.0067 - val_loss: 0.0056\n",
      "Epoch 31/50\n",
      " - 6s - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 32/50\n",
      " - 6s - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 33/50\n",
      " - 6s - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 34/50\n",
      " - 6s - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 35/50\n",
      " - 6s - loss: 0.0063 - val_loss: 0.0054\n",
      "Epoch 36/50\n",
      " - 7s - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      " - 7s - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 38/50\n",
      " - 6s - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 39/50\n",
      " - 6s - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 40/50\n",
      " - 6s - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 41/50\n",
      " - 6s - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 42/50\n",
      " - 6s - loss: 0.0065 - val_loss: 0.0054\n",
      "Epoch 43/50\n",
      " - 6s - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 44/50\n",
      " - 6s - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 45/50\n",
      " - 6s - loss: 0.0064 - val_loss: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      " - 6s - loss: 0.0062 - val_loss: 0.0053\n",
      "Epoch 47/50\n",
      " - 8s - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 48/50\n",
      " - 7s - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 49/50\n",
      " - 7s - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 50/50\n",
      " - 7s - loss: 0.0062 - val_loss: 0.0058\n",
      "Inverted Mean Absolute Error: 49.285313\n",
      "Inverted Test RMSE: 65.698\n",
      "Inverted Test R^2: 0.998\n"
     ]
    }
   ],
   "source": [
    "for node in demands:\n",
    "    # split into train and test sets\n",
    "    demand_values = node.values\n",
    "    train, test = train_test_split(demand_values, test_size=0.2, random_state=0)\n",
    "\n",
    "    # split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    # make predictions on the test data\n",
    "    y_pred = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_test_y = concatenate((test_y, test_X[:, -96:]), axis=1)\n",
    "    test_y_inverse = scaler.inverse_transform(inv_test_y)\n",
    "    test_y_inverse = test_y_inverse[:,0]\n",
    "\n",
    "    y_pred = y_pred.reshape((len(y_pred), 1))\n",
    "    inv_y_pred = concatenate((y_pred, test_X[:, -96:]), axis=1)\n",
    "    y_pred_inverse = scaler.inverse_transform(inv_y_pred)\n",
    "    y_pred_inverse = y_pred_inverse[:,0]\n",
    "\n",
    "    # evaluate scaled errors\n",
    "    mae = mean_absolute_error(test_y_inverse, y_pred_inverse)\n",
    "    print('Inverted Mean Absolute Error:', mae)\n",
    "    rmse = sqrt(mean_squared_error(test_y_inverse, y_pred_inverse))\n",
    "    print('Inverted Test RMSE: %.3f' % rmse)\n",
    "    r2 = r2_score(test_y_inverse, y_pred_inverse)\n",
    "    print('Inverted Test R^2: %.3f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      "70080/70080 [==============================] - 7s 102us/step - loss: 0.0267 - val_loss: 0.0084\n",
      "Epoch 2/50\n",
      "70080/70080 [==============================] - 6s 82us/step - loss: 0.0085 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "70080/70080 [==============================] - 6s 84us/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 4/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0055 - val_loss: 0.0042\n",
      "Epoch 5/50\n",
      "70080/70080 [==============================] - 6s 88us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 6/50\n",
      "70080/70080 [==============================] - 6s 90us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 7/50\n",
      "70080/70080 [==============================] - 7s 104us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 8/50\n",
      "70080/70080 [==============================] - 8s 110us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 9/50\n",
      "70080/70080 [==============================] - 7s 105us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 10/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 11/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 12/50\n",
      "70080/70080 [==============================] - 8s 112us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "70080/70080 [==============================] - 10s 146us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "70080/70080 [==============================] - 7s 102us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 15/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 16/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 17/50\n",
      "70080/70080 [==============================] - 7s 101us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 18/50\n",
      "70080/70080 [==============================] - 7s 101us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 19/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 20/50\n",
      "70080/70080 [==============================] - 7s 104us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 21/50\n",
      "70080/70080 [==============================] - 7s 106us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 24/50\n",
      "70080/70080 [==============================] - 7s 105us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 25/50\n",
      "70080/70080 [==============================] - 7s 102us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "70080/70080 [==============================] - 8s 110us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 27/50\n",
      "70080/70080 [==============================] - 8s 119us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 28/50\n",
      "70080/70080 [==============================] - 9s 125us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 30/50\n",
      "70080/70080 [==============================] - 7s 101us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 31/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 32/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 33/50\n",
      "70080/70080 [==============================] - 8s 108us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "70080/70080 [==============================] - 7s 101us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 35/50\n",
      "70080/70080 [==============================] - 7s 105us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 36/50\n",
      "70080/70080 [==============================] - 7s 107us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 37/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 38/50\n",
      "70080/70080 [==============================] - 9s 124us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 39/50\n",
      "70080/70080 [==============================] - 7s 105us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "70080/70080 [==============================] - 9s 132us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 41/50\n",
      "70080/70080 [==============================] - 8s 110us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 43/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 44/50\n",
      "70080/70080 [==============================] - 8s 110us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 45/50\n",
      "70080/70080 [==============================] - 8s 114us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 46/50\n",
      "70080/70080 [==============================] - 9s 134us/step - loss: 0.0015 - val_loss: 9.3229e-04\n",
      "Epoch 47/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 48/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 49/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 50/50\n",
      "70080/70080 [==============================] - 7s 101us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Inverted Mean Absolute Error: 11.035886\n",
      "Inverted Test RMSE: 16.716\n",
      "Inverted Test R^2: 1.000\n",
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      "70080/70080 [==============================] - 8s 120us/step - loss: 0.0141 - val_loss: 0.0029\n",
      "Epoch 2/50\n",
      "70080/70080 [==============================] - 7s 95us/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 3/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 4/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 5/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 6/50\n",
      "70080/70080 [==============================] - 7s 94us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 7/50\n",
      "70080/70080 [==============================] - 7s 95us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 8/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 9/50\n",
      "70080/70080 [==============================] - 7s 95us/step - loss: 0.0037 - val_loss: 0.0103\n",
      "Epoch 10/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0027 - val_loss: 0.0073\n",
      "Epoch 13/50\n",
      "70080/70080 [==============================] - 7s 95us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 14/50\n",
      "70080/70080 [==============================] - 7s 95us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 15/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 16/50\n",
      "70080/70080 [==============================] - 7s 95us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 18/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 19/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 21/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 22/50\n",
      "70080/70080 [==============================] - 8s 112us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 23/50\n",
      "70080/70080 [==============================] - 7s 107us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 24/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 26/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      "70080/70080 [==============================] - 9s 125us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "70080/70080 [==============================] - 10s 145us/step - loss: 0.0021 - val_loss: 0.0042\n",
      "Epoch 30/50\n",
      "70080/70080 [==============================] - 8s 112us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 31/50\n",
      "70080/70080 [==============================] - 8s 109us/step - loss: 0.0022 - val_loss: 8.8959e-04\n",
      "Epoch 32/50\n",
      "70080/70080 [==============================] - 8s 114us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "70080/70080 [==============================] - 7s 107us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "70080/70080 [==============================] - 8s 110us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 35/50\n",
      "70080/70080 [==============================] - 8s 112us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 36/50\n",
      "70080/70080 [==============================] - 7s 106us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 38/50\n",
      "70080/70080 [==============================] - 7s 106us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 39/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 40/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 41/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 42/50\n",
      "70080/70080 [==============================] - 7s 101us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 43/50\n",
      "70080/70080 [==============================] - 14s 199us/step - loss: 0.0018 - val_loss: 7.9343e-04\n",
      "Epoch 44/50\n",
      "70080/70080 [==============================] - 9s 130us/step - loss: 0.0017 - val_loss: 9.6877e-04\n",
      "Epoch 45/50\n",
      "70080/70080 [==============================] - 15s 219us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "70080/70080 [==============================] - 11s 158us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 47/50\n",
      "70080/70080 [==============================] - 13s 184us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 48/50\n",
      "70080/70080 [==============================] - 13s 188us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "70080/70080 [==============================] - 11s 156us/step - loss: 0.0018 - val_loss: 9.0683e-04\n",
      "Epoch 50/50\n",
      "70080/70080 [==============================] - 12s 170us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Inverted Mean Absolute Error: 25.479086\n",
      "Inverted Test RMSE: 27.440\n",
      "Inverted Test R^2: 0.999\n",
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      "70080/70080 [==============================] - 13s 190us/step - loss: 0.0101 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "70080/70080 [==============================] - 8s 111us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 3/50\n",
      "70080/70080 [==============================] - 9s 125us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 4/50\n",
      "70080/70080 [==============================] - 9s 127us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 5/50\n",
      "70080/70080 [==============================] - 9s 130us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 6/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 8/50\n",
      "70080/70080 [==============================] - 7s 102us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 9/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 10/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 12/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0021 - val_loss: 9.7960e-04\n",
      "Epoch 13/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 14/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 15/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 16/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0019 - val_loss: 0.0075\n",
      "Epoch 18/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 19/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 20/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 22/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 23/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 24/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 25/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 26/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0016 - val_loss: 7.4897e-04\n",
      "Epoch 27/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 28/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 29/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 31/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0015 - val_loss: 8.4383e-04\n",
      "Epoch 32/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 33/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 36/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 37/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "70080/70080 [==============================] - 7s 101us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 39/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 40/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0013 - val_loss: 6.7704e-04\n",
      "Epoch 41/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 42/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 43/50\n",
      "70080/70080 [==============================] - 7s 99us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 45/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 46/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0012 - val_loss: 6.0201e-04\n",
      "Epoch 47/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0013 - val_loss: 8.5876e-04\n",
      "Epoch 48/50\n",
      "70080/70080 [==============================] - 7s 97us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0013 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "70080/70080 [==============================] - 7s 98us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Inverted Mean Absolute Error: 15.811977\n",
      "Inverted Test RMSE: 17.195\n",
      "Inverted Test R^2: 1.000\n"
     ]
    }
   ],
   "source": [
    "for node in pressures:\n",
    "    # split into train and test sets\n",
    "    pressure_values = node.values\n",
    "    train, test = train_test_split(pressure_values, test_size=0.2, random_state=0)\n",
    "\n",
    "    # split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "    \n",
    "    # make predictions on the test data\n",
    "    y_pred = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_test_y = concatenate((test_y, test_X[:, -96:]), axis=1)\n",
    "    test_y_inverse = scaler.inverse_transform(inv_test_y)\n",
    "    test_y_inverse = test_y_inverse[:,0]\n",
    "\n",
    "    y_pred = y_pred.reshape((len(y_pred), 1))\n",
    "    inv_y_pred = concatenate((y_pred, test_X[:, -96:]), axis=1)\n",
    "    y_pred_inverse = scaler.inverse_transform(inv_y_pred)\n",
    "    y_pred_inverse = y_pred_inverse[:,0]\n",
    "\n",
    "    # evaluate scaled errors\n",
    "    mae = mean_absolute_error(test_y_inverse, y_pred_inverse)\n",
    "    print('Inverted Mean Absolute Error:', mae)\n",
    "    rmse = sqrt(mean_squared_error(test_y_inverse, y_pred_inverse))\n",
    "    print('Inverted Test RMSE: %.3f' % rmse)\n",
    "    r2 = r2_score(test_y_inverse, y_pred_inverse)\n",
    "    print('Inverted Test R^2: %.3f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      "70080/70080 [==============================] - 8s 113us/step - loss: 0.0080 - val_loss: 0.0059\n",
      "Epoch 2/50\n",
      "70080/70080 [==============================] - 6s 84us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 3/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0032 - val_loss: 9.6646e-04\n",
      "Epoch 4/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0030 - val_loss: 0.0072\n",
      "Epoch 5/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 6/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0028 - val_loss: 9.0210e-04\n",
      "Epoch 7/50\n",
      "70080/70080 [==============================] - 6s 83us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 8/50\n",
      "70080/70080 [==============================] - 6s 91us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 9/50\n",
      "70080/70080 [==============================] - 6s 90us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 10/50\n",
      "70080/70080 [==============================] - 6s 82us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 11/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0022 - val_loss: 7.6734e-04\n",
      "Epoch 12/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0018 - val_loss: 9.9942e-04\n",
      "Epoch 14/50\n",
      "70080/70080 [==============================] - 6s 88us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 15/50\n",
      "70080/70080 [==============================] - 6s 90us/step - loss: 0.0016 - val_loss: 7.4735e-04\n",
      "Epoch 16/50\n",
      "70080/70080 [==============================] - 6s 88us/step - loss: 0.0016 - val_loss: 8.0794e-04\n",
      "Epoch 17/50\n",
      "70080/70080 [==============================] - 6s 88us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 18/50\n",
      "70080/70080 [==============================] - 6s 82us/step - loss: 0.0015 - val_loss: 8.7834e-04\n",
      "Epoch 19/50\n",
      "70080/70080 [==============================] - 6s 88us/step - loss: 0.0017 - val_loss: 6.0207e-04\n",
      "Epoch 20/50\n",
      "70080/70080 [==============================] - 6s 89us/step - loss: 0.0014 - val_loss: 6.4565e-04\n",
      "Epoch 21/50\n",
      "70080/70080 [==============================] - 7s 96us/step - loss: 0.0015 - val_loss: 5.7309e-04\n",
      "Epoch 22/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 23/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 24/50\n",
      "70080/70080 [==============================] - 5s 77us/step - loss: 0.0014 - val_loss: 4.8086e-04\n",
      "Epoch 25/50\n",
      "70080/70080 [==============================] - 5s 77us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 26/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0014 - val_loss: 5.6527e-04\n",
      "Epoch 27/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 28/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 29/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0013 - val_loss: 7.6377e-04\n",
      "Epoch 30/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 31/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 32/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0011 - val_loss: 9.3497e-04\n",
      "Epoch 33/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Epoch 34/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 36/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0013 - val_loss: 5.7645e-04\n",
      "Epoch 37/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0010 - val_loss: 9.4035e-04\n",
      "Epoch 38/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 9.6950e-04 - val_loss: 0.0031\n",
      "Epoch 39/50\n",
      "70080/70080 [==============================] - 6s 81us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0011 - val_loss: 8.3203e-04\n",
      "Epoch 41/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0010 - val_loss: 6.8349e-04\n",
      "Epoch 42/50\n",
      "70080/70080 [==============================] - 6s 81us/step - loss: 0.0010 - val_loss: 9.3582e-04\n",
      "Epoch 43/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 9.9834e-04 - val_loss: 7.7349e-04\n",
      "Epoch 44/50\n",
      "70080/70080 [==============================] - 6s 91us/step - loss: 0.0010 - val_loss: 6.0028e-04\n",
      "Epoch 45/50\n",
      "70080/70080 [==============================] - 10s 139us/step - loss: 0.0011 - val_loss: 6.9659e-04\n",
      "Epoch 46/50\n",
      "70080/70080 [==============================] - 5s 76us/step - loss: 0.0011 - val_loss: 5.8480e-04\n",
      "Epoch 47/50\n",
      "70080/70080 [==============================] - 5s 77us/step - loss: 0.0010 - val_loss: 4.8699e-04\n",
      "Epoch 48/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 9.8578e-04 - val_loss: 0.0015\n",
      "Epoch 49/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 9.5994e-04 - val_loss: 4.5130e-04\n",
      "Epoch 50/50\n",
      "70080/70080 [==============================] - 7s 104us/step - loss: 9.8732e-04 - val_loss: 0.0017\n",
      "Inverted Mean Absolute Error: 14.809023\n",
      "Inverted Test RMSE: 16.960\n",
      "Inverted Test R^2: 1.000\n",
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      "70080/70080 [==============================] - 13s 192us/step - loss: 0.0175 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "70080/70080 [==============================] - 9s 122us/step - loss: 0.0073 - val_loss: 0.0051\n",
      "Epoch 3/50\n",
      "70080/70080 [==============================] - 6s 90us/step - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 4/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "70080/70080 [==============================] - 7s 94us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 6/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 7/50\n",
      "70080/70080 [==============================] - 6s 82us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 8/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 9/50\n",
      "70080/70080 [==============================] - 6s 88us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 10/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 11/50\n",
      "70080/70080 [==============================] - 6s 82us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 12/50\n",
      "70080/70080 [==============================] - 6s 89us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 13/50\n",
      "70080/70080 [==============================] - 7s 93us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 14/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 16/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0035 - val_loss: 0.0063\n",
      "Epoch 17/50\n",
      "70080/70080 [==============================] - 6s 82us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 18/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 19/50\n",
      "70080/70080 [==============================] - 6s 88us/step - loss: 0.0035 - val_loss: 0.0092\n",
      "Epoch 20/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 22/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 23/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 25/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 27/50\n",
      "70080/70080 [==============================] - 6s 89us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 28/50\n",
      "70080/70080 [==============================] - 6s 81us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 29/50\n",
      "70080/70080 [==============================] - 6s 84us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 31/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 33/50\n",
      "70080/70080 [==============================] - 6s 81us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 34/50\n",
      "70080/70080 [==============================] - 6s 84us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 35/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 36/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "70080/70080 [==============================] - 5s 76us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 38/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 39/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 40/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 41/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 42/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 43/50\n",
      "70080/70080 [==============================] - 5s 73us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 44/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 46/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 47/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 48/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 49/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Inverted Mean Absolute Error: 24.790043\n",
      "Inverted Test RMSE: 29.490\n",
      "Inverted Test R^2: 1.000\n",
      "(70080, 1, 95) (70080,) (17520, 1, 95) (17520,)\n",
      "Train on 70080 samples, validate on 17520 samples\n",
      "Epoch 1/50\n",
      "70080/70080 [==============================] - 7s 100us/step - loss: 0.0280 - val_loss: 0.0222\n",
      "Epoch 2/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0148 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0121 - val_loss: 0.0096\n",
      "Epoch 4/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 5/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0109 - val_loss: 0.0088\n",
      "Epoch 6/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 7/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 8/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 9/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0099 - val_loss: 0.0075\n",
      "Epoch 10/50\n",
      "70080/70080 [==============================] - 5s 76us/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 11/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0099 - val_loss: 0.0078\n",
      "Epoch 12/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0097 - val_loss: 0.0126\n",
      "Epoch 13/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 14/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 15/50\n",
      "70080/70080 [==============================] - 5s 74us/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 16/50\n",
      "70080/70080 [==============================] - 5s 75us/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 17/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 18/50\n",
      "70080/70080 [==============================] - 7s 103us/step - loss: 0.0091 - val_loss: 0.0078\n",
      "Epoch 19/50\n",
      "70080/70080 [==============================] - 6s 92us/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 20/50\n",
      "70080/70080 [==============================] - 8s 120us/step - loss: 0.0091 - val_loss: 0.0088\n",
      "Epoch 21/50\n",
      "70080/70080 [==============================] - 9s 128us/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 22/50\n",
      "70080/70080 [==============================] - 11s 155us/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 23/50\n",
      "70080/70080 [==============================] - 6s 91us/step - loss: 0.0090 - val_loss: 0.0073\n",
      "Epoch 24/50\n",
      "70080/70080 [==============================] - 6s 81us/step - loss: 0.0089 - val_loss: 0.0078\n",
      "Epoch 25/50\n",
      "70080/70080 [==============================] - 6s 90us/step - loss: 0.0090 - val_loss: 0.0075\n",
      "Epoch 26/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 27/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0089 - val_loss: 0.0077\n",
      "Epoch 28/50\n",
      "70080/70080 [==============================] - 5s 77us/step - loss: 0.0089 - val_loss: 0.0074\n",
      "Epoch 29/50\n",
      "70080/70080 [==============================] - 6s 87us/step - loss: 0.0086 - val_loss: 0.0074\n",
      "Epoch 30/50\n",
      "70080/70080 [==============================] - 6s 80us/step - loss: 0.0088 - val_loss: 0.0085\n",
      "Epoch 31/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 32/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 33/50\n",
      "70080/70080 [==============================] - 5s 77us/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 34/50\n",
      "70080/70080 [==============================] - 5s 78us/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 35/50\n",
      "70080/70080 [==============================] - 6s 82us/step - loss: 0.0088 - val_loss: 0.0120\n",
      "Epoch 36/50\n",
      "70080/70080 [==============================] - 6s 86us/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 37/50\n",
      "70080/70080 [==============================] - 10s 136us/step - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 38/50\n",
      "70080/70080 [==============================] - 12s 165us/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 39/50\n",
      "70080/70080 [==============================] - 14s 195us/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 40/50\n",
      "70080/70080 [==============================] - 11s 158us/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 41/50\n",
      "70080/70080 [==============================] - 9s 124us/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 42/50\n",
      "70080/70080 [==============================] - 6s 91us/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 43/50\n",
      "70080/70080 [==============================] - 6s 81us/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "70080/70080 [==============================] - 9s 125us/step - loss: 0.0084 - val_loss: 0.0092\n",
      "Epoch 45/50\n",
      "70080/70080 [==============================] - 10s 141us/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 46/50\n",
      "70080/70080 [==============================] - 5s 77us/step - loss: 0.0084 - val_loss: 0.0073\n",
      "Epoch 47/50\n",
      "70080/70080 [==============================] - 6s 79us/step - loss: 0.0082 - val_loss: 0.0083\n",
      "Epoch 48/50\n",
      "70080/70080 [==============================] - 6s 92us/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70080/70080 [==============================] - 6s 90us/step - loss: 0.0083 - val_loss: 0.0074\n",
      "Epoch 50/50\n",
      "70080/70080 [==============================] - 6s 85us/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Inverted Mean Absolute Error: 60.795097\n",
      "Inverted Test RMSE: 81.062\n",
      "Inverted Test R^2: 0.997\n"
     ]
    }
   ],
   "source": [
    "for node in flows:\n",
    "    # split into train and test sets\n",
    "    flow_values = node.values\n",
    "    train, test = train_test_split(flow_values, test_size=0.2, random_state=0)\n",
    "\n",
    "    # split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "    \n",
    "    # make predictions on the test data\n",
    "    y_pred = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_test_y = concatenate((test_y, test_X[:, -96:]), axis=1)\n",
    "    test_y_inverse = scaler.inverse_transform(inv_test_y)\n",
    "    test_y_inverse = test_y_inverse[:,0]\n",
    "\n",
    "    y_pred = y_pred.reshape((len(y_pred), 1))\n",
    "    inv_y_pred = concatenate((y_pred, test_X[:, -96:]), axis=1)\n",
    "    y_pred_inverse = scaler.inverse_transform(inv_y_pred)\n",
    "    y_pred_inverse = y_pred_inverse[:,0]\n",
    "\n",
    "    # evaluate scaled errors\n",
    "    mae = mean_absolute_error(test_y_inverse, y_pred_inverse)\n",
    "    print('Inverted Mean Absolute Error:', mae)\n",
    "    rmse = sqrt(mean_squared_error(test_y_inverse, y_pred_inverse))\n",
    "    print('Inverted Test RMSE: %.3f' % rmse)\n",
    "    r2 = r2_score(test_y_inverse, y_pred_inverse)\n",
    "    print('Inverted Test R^2: %.3f' % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
